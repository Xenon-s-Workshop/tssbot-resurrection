import os
import json
import csv
from pathlib import Path
from typing import List, Dict, Optional
import asyncio
from datetime import datetime
from threading import Lock

import google.generativeai as genai
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    CallbackQueryHandler,
    ContextTypes,
    filters,
)
from pdf2image import convert_from_path
from PIL import Image

# Import prompts
from prompts import get_extraction_prompt, get_generation_prompt

# Configuration
class Config:
    TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
    GEMINI_API_KEYS = os.getenv("GEMINI_API_KEYS", "").split(",")
    TEMP_DIR = Path("temp")
    OUTPUT_DIR = Path("output")
    MAX_CONCURRENT_IMAGES = 5
    MAX_QUEUE_SIZE = 10
    
    GEMINI_MODEL = "gemini-2.0-flash-exp"
    
    GENERATION_CONFIG = {
        "temperature": 0.1,
        "top_p": 0.95,
        "top_k": 40,
        "max_output_tokens": 8192,
    }
    
    SAFETY_SETTINGS = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]
    
    def __init__(self):
        if not self.TELEGRAM_BOT_TOKEN:
            raise ValueError("TELEGRAM_BOT_TOKEN environment variable is required!")
        if not self.GEMINI_API_KEYS or self.GEMINI_API_KEYS == ['']:
            raise ValueError("GEMINI_API_KEYS environment variable is required!")
        
        self.TEMP_DIR.mkdir(exist_ok=True)
        self.OUTPUT_DIR.mkdir(exist_ok=True)

config = Config()

# Gemini API Key Rotation
class GeminiAPIRotator:
    def __init__(self, api_keys: List[str]):
        self.api_keys = [key.strip() for key in api_keys if key.strip()]
        self.current_index = 0
        self.lock = Lock()
        
        if not self.api_keys:
            raise ValueError("No valid Gemini API keys provided!")
    
    def get_next_key(self) -> str:
        with self.lock:
            key = self.api_keys[self.current_index]
            self.current_index = (self.current_index + 1) % len(self.api_keys)
            return key

api_rotator = GeminiAPIRotator(config.GEMINI_API_KEYS)

# Task Queue Manager
class TaskQueue:
    def __init__(self):
        self.queue = []
        self.lock = Lock()
        self.processing = set()
    
    def add_task(self, user_id: int, task_data: Dict) -> int:
        with self.lock:
            # Check if user already has task in queue or processing
            if user_id in self.processing:
                return -2  # Already processing
            
            for task in self.queue:
                if task['user_id'] == user_id:
                    return -2  # Already in queue
            
            if len(self.queue) >= config.MAX_QUEUE_SIZE:
                return -1  # Queue full
            
            task = {
                'user_id': user_id,
                'data': task_data,
                'timestamp': datetime.now()
            }
            self.queue.append(task)
            return len(self.queue)
    
    def get_next_task(self) -> Optional[Dict]:
        with self.lock:
            if self.queue:
                return self.queue.pop(0)
            return None
    
    def get_position(self, user_id: int) -> int:
        with self.lock:
            for idx, task in enumerate(self.queue):
                if task['user_id'] == user_id:
                    return idx + 1
            return 0
    
    def is_processing(self, user_id: int) -> bool:
        with self.lock:
            return user_id in self.processing
    
    def set_processing(self, user_id: int, status: bool):
        with self.lock:
            if status:
                self.processing.add(user_id)
            else:
                self.processing.discard(user_id)
    
    def get_queue_size(self) -> int:
        with self.lock:
            return len(self.queue)

task_queue = TaskQueue()

# PDF Processing Functions
class PDFProcessor:
    @staticmethod
    async def pdf_to_images(pdf_path: Path, page_range: Optional[tuple] = None) -> List[Image.Image]:
        try:
            if page_range:
                first_page, last_page = page_range
                images = convert_from_path(
                    pdf_path,
                    first_page=first_page,
                    last_page=last_page,
                    dpi=300
                )
            else:
                images = convert_from_path(pdf_path, dpi=300)
            
            return images
        except Exception as e:
            raise Exception(f"Error converting PDF to images: {str(e)}")
    
    @staticmethod
    async def process_single_image(image: Image.Image, image_idx: int, mode: str, retry_count: int = 3) -> Optional[tuple]:
        for attempt in range(retry_count):
            try:
                api_key = api_rotator.get_next_key()
                genai.configure(api_key=api_key)
                
                model = genai.GenerativeModel(
                    model_name=config.GEMINI_MODEL,
                    generation_config=config.GENERATION_CONFIG,
                    safety_settings=config.SAFETY_SETTINGS
                )
                
                # Select prompt based on mode
                prompt = get_extraction_prompt() if mode == "extraction" else get_generation_prompt()
                
                print(f"Processing image {image_idx} in {mode} mode with {config.GEMINI_MODEL}")
                
                response = model.generate_content([prompt, image])
                response_text = response.text.strip()
                
                if response_text.startswith("```json"):
                    response_text = response_text[7:]
                if response_text.startswith("```"):
                    response_text = response_text[3:]
                if response_text.endswith("```"):
                    response_text = response_text[:-3]
                
                response_text = response_text.strip()
                questions = json.loads(response_text)
                
                print(f"‚úÖ Successfully processed image {image_idx}")
                return (image_idx, questions)
                
            except json.JSONDecodeError as e:
                print(f"JSON decode error for image {image_idx}, attempt {attempt + 1}: {str(e)}")
                if attempt == retry_count - 1:
                    return (image_idx, None)
                await asyncio.sleep(1)
                
            except Exception as e:
                print(f"Error processing image {image_idx}, attempt {attempt + 1}: {str(e)}")
                if attempt == retry_count - 1:
                    return (image_idx, None)
                await asyncio.sleep(2)
        
        return (image_idx, None)
    
    @staticmethod
    async def process_images_parallel(images: List[Image.Image], mode: str, progress_callback=None) -> List[Dict]:
        all_questions = []
        total_images = len(images)
        
        for batch_start in range(0, total_images, config.MAX_CONCURRENT_IMAGES):
            batch_end = min(batch_start + config.MAX_CONCURRENT_IMAGES, total_images)
            batch_images = images[batch_start:batch_end]
            
            tasks = []
            for i, image in enumerate(batch_images):
                image_idx = batch_start + i + 1
                task = PDFProcessor.process_single_image(image, image_idx, mode)
                tasks.append(task)
            
            results = await asyncio.gather(*tasks)
            
            for image_idx, questions in results:
                if progress_callback:
                    await progress_callback(image_idx, total_images)
                
                if questions:
                    all_questions.extend(questions)
            
            if batch_end < total_images:
                await asyncio.sleep(0.5)
        
        return all_questions

# CSV Generation
class CSVGenerator:
    @staticmethod
    def questions_to_csv(questions: List[Dict], output_path: Path):
        with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = [
                'questions', 'option1', 'option2', 'option3', 'option4', 
                'option5', 'answer', 'explanation', 'type', 'section'
            ]
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            
            for q in questions:
                options = q.get('options', [])
                while len(options) < 4:
                    options.append('')
                
                correct_index = q.get('correct_answer_index', -1)
                answer = str(correct_index + 1) if correct_index >= 0 else ''
                
                row = {
                    'questions': q.get('question_description', ''),
                    'option1': options[0] if len(options) > 0 else '',
                    'option2': options[1] if len(options) > 1 else '',
                    'option3': options[2] if len(options) > 2 else '',
                    'option4': options[3] if len(options) > 3 else '',
                    'option5': '',
                    'answer': answer,
                    'explanation': q.get('explanation', ''),
                    'type': '1',  # Always 1
                    'section': '1'  # Always 1
                }
                writer.writerow(row)

# Queue Processor (runs in background)
class QueueProcessor:
    def __init__(self, bot):
        self.bot = bot
        self.running = False
    
    async def start(self):
        """Start processing queue"""
        if self.running:
            return
        
        self.running = True
        print("üîÑ Queue processor started")
        
        while self.running:
            try:
                task = task_queue.get_next_task()
                
                if task:
                    user_id = task['user_id']
                    task_data = task['data']
                    
                    task_queue.set_processing(user_id, True)
                    
                    try:
                        await self.bot.process_pdf(
                            user_id=user_id,
                            pdf_path=task_data['pdf_path'],
                            page_range=task_data['page_range'],
                            mode=task_data['mode'],
                            context=task_data['context']
                        )
                    except Exception as e:
                        print(f"Error processing task for user {user_id}: {str(e)}")
                        try:
                            await task_data['context'].bot.send_message(
                                chat_id=user_id,
                                text=f"‚ùå Error processing your PDF: {str(e)}"
                            )
                        except:
                            pass
                    finally:
                        task_queue.set_processing(user_id, False)
                    
                    await asyncio.sleep(1)
                else:
                    # No tasks, wait a bit
                    await asyncio.sleep(2)
                    
            except Exception as e:
                print(f"Queue processor error: {str(e)}")
                await asyncio.sleep(5)
    
    def stop(self):
        """Stop processing queue"""
        self.running = False
        print("üõë Queue processor stopped")

# Telegram Bot Handlers
class TelegramBot:
    def __init__(self):
        self.user_states = {}
    
    async def start(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        await update.message.reply_text(
            "Welcome! üëã\n\n"
            "Send me a PDF file to extract or generate MCQ questions.\n\n"
            "ü§ñ Powered by Gemini 2.0 Flash\n\n"
            "Commands:\n"
            "/start - Start the bot\n"
            "/help - Show help message\n"
            "/queue - Check your queue position\n"
            "/cancel - Cancel your current task\n"
            "/model - Show current AI model info"
        )
    
    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        await update.message.reply_text(
            "üìö *How to use:*\n\n"
            "1. Send me a PDF file\n"
            "2. Choose mode:\n"
            "   ‚Ä¢ *Extraction* - Extract existing questions\n"
            "   ‚Ä¢ *Generation* - Generate new questions from textbook\n"
            "3. Optionally specify page range\n"
            "4. Get your CSV file\n\n"
            "*Features:*\n"
            "‚úì Gemini 2.0 Flash AI\n"
            "‚úì Two processing modes\n"
            "‚úì Automatic answer detection\n"
            "‚úì Bengali explanations\n"
            "‚úì Task queue system\n"
            "‚úì Parallel processing (5x faster)",
            parse_mode='Markdown'
        )
    
    async def model_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        queue_size = task_queue.get_queue_size()
        await update.message.reply_text(
            f"ü§ñ *AI Model Information:*\n\n"
            f"Model: `{config.GEMINI_MODEL}`\n"
            f"Temperature: {config.GENERATION_CONFIG['temperature']}\n"
            f"Max Tokens: {config.GENERATION_CONFIG['max_output_tokens']}\n"
            f"Parallel Workers: {config.MAX_CONCURRENT_IMAGES}\n"
            f"API Keys: {len(config.GEMINI_API_KEYS)}\n"
            f"Queue Size: {queue_size}/{config.MAX_QUEUE_SIZE}",
            parse_mode='Markdown'
        )
    
    async def queue_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        user_id = update.effective_user.id
        
        if task_queue.is_processing(user_id):
            await update.message.reply_text("‚öôÔ∏è Your task is currently being processed!")
        else:
            position = task_queue.get_position(user_id)
            if position > 0:
                await update.message.reply_text(
                    f"üìã Your position in queue: {position}\n"
                    f"‚è≥ Estimated wait: ~{position * 2} minutes"
                )
            else:
                await update.message.reply_text("‚ùå You don't have any tasks in queue.")
    
    async def cancel_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        user_id = update.effective_user.id
        
        if user_id in self.user_states:
            pdf_path = self.user_states[user_id].get('pdf_path')
            if pdf_path and pdf_path.exists():
                pdf_path.unlink(missing_ok=True)
            del self.user_states[user_id]
            task_queue.set_processing(user_id, False)
            await update.message.reply_text("‚úÖ Task cancelled successfully!")
        else:
            await update.message.reply_text("‚ùå No active task to cancel.")
    
    async def handle_document(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        user_id = update.effective_user.id
        document = update.message.document
        
        if not document.file_name.endswith('.pdf'):
            await update.message.reply_text("‚ùå Please send a PDF file only.")
            return
        
        if user_id in self.user_states or task_queue.is_processing(user_id):
            await update.message.reply_text(
                "‚ö†Ô∏è You already have a task in progress.\n"
                "Use /cancel to cancel the current task."
            )
            return
        
        processing_msg = await update.message.reply_text("üì• Downloading PDF...")
        
        try:
            file = await context.bot.get_file(document.file_id)
            pdf_path = config.TEMP_DIR / f"{user_id}_{document.file_name}"
            await file.download_to_drive(pdf_path)
            
            # Ask for mode selection
            keyboard = [
                [InlineKeyboardButton("üì§ Extraction Mode", callback_data="mode_extraction")],
                [InlineKeyboardButton("‚ú® Generation Mode", callback_data="mode_generation")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            self.user_states[user_id] = {'pdf_path': pdf_path}
            
            await processing_msg.edit_text(
                "üìÑ PDF received!\n\n"
                "Choose processing mode:\n\n"
                "üì§ *Extraction Mode*\n"
                "Extract existing MCQs from PDF\n\n"
                "‚ú® *Generation Mode*\n"
                "Generate new MCQs from textbook content",
                reply_markup=reply_markup,
                parse_mode='Markdown'
            )
            
        except Exception as e:
            await processing_msg.edit_text(f"‚ùå Error downloading PDF: {str(e)}")
    
    async def button_callback(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        query = update.callback_query
        await query.answer()
        
        user_id = update.effective_user.id
        
        if query.data.startswith("mode_"):
            mode = query.data.split("_")[1]
            self.user_states[user_id]['mode'] = mode
            
            mode_name = "Extraction" if mode == "extraction" else "Generation"
            
            keyboard = [
                [InlineKeyboardButton("All Pages", callback_data="all_pages")],
                [InlineKeyboardButton("Specify Range", callback_data="specify_range")]
            ]
            reply_markup = InlineKeyboardMarkup(keyboard)
            
            await query.edit_message_text(
                f"‚úÖ Mode selected: *{mode_name}*\n\n"
                f"Choose page range:",
                reply_markup=reply_markup,
                parse_mode='Markdown'
            )
        
        elif query.data == "all_pages":
            await self.add_to_queue(update, context, user_id, None)
        
        elif query.data == "specify_range":
            await query.edit_message_text(
                "Please send the page range in format: start-end\n"
                "Example: 1-10 or 5-8"
            )
            self.user_states[user_id]['waiting_for_range'] = True
    
    async def handle_text(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        user_id = update.effective_user.id
        
        if user_id not in self.user_states:
            return
        
        if self.user_states[user_id].get('waiting_for_range'):
            try:
                text = update.message.text.strip()
                parts = text.split('-')
                
                if len(parts) != 2:
                    await update.message.reply_text("‚ùå Invalid format. Use: start-end (e.g., 1-10)")
                    return
                
                start_page = int(parts[0])
                end_page = int(parts[1])
                
                if start_page < 1 or end_page < start_page:
                    await update.message.reply_text("‚ùå Invalid page range")
                    return
                
                page_range = (start_page, end_page)
                self.user_states[user_id]['waiting_for_range'] = False
                
                await self.add_to_queue(update, context, user_id, page_range)
                
            except ValueError:
                await update.message.reply_text("‚ùå Invalid page numbers. Use numbers only.")
    
    async def add_to_queue(self, update: Update, context: ContextTypes.DEFAULT_TYPE,
                          user_id: int, page_range: Optional[tuple]):
        if user_id not in self.user_states:
            return
        
        mode = self.user_states[user_id].get('mode', 'extraction')
        
        task_data = {
            'pdf_path': self.user_states[user_id]['pdf_path'],
            'page_range': page_range,
            'mode': mode,
            'context': context
        }
        
        position = task_queue.add_task(user_id, task_data)
        
        if position == -1:
            message_text = "‚ùå Queue is full. Please try again later."
        elif position == -2:
            message_text = "‚ö†Ô∏è You already have a task in queue or being processed."
        else:
            mode_name = "Extraction" if mode == "extraction" else "Generation"
            message_text = (
                f"‚úÖ Added to queue!\n"
                f"üìã Position: {position}\n"
                f"‚è≥ Estimated wait: ~{position * 2} minutes\n"
                f"üéØ Mode: {mode_name}\n"
                f"ü§ñ {config.GEMINI_MODEL}"
            )
        
        if update.callback_query:
            await update.callback_query.message.edit_text(message_text)
        else:
            await update.message.reply_text(message_text)
    
    async def process_pdf(self, user_id: int, pdf_path: Path, 
                         page_range: Optional[tuple], mode: str, context: ContextTypes.DEFAULT_TYPE):
        try:
            mode_name = "Extraction" if mode == "extraction" else "Generation"
            mode_emoji = "üì§" if mode == "extraction" else "‚ú®"
            
            message = await context.bot.send_message(
                chat_id=user_id,
                text=f"üîÑ Processing your PDF...\n{mode_emoji} Mode: {mode_name}\nü§ñ Using {config.GEMINI_MODEL}"
            )
            
            await message.edit_text("üìÑ Converting PDF to images...")
            images = await PDFProcessor.pdf_to_images(pdf_path, page_range)
            
            await message.edit_text(
                f"üñºÔ∏è Processing {len(images)} pages in parallel...\n"
                f"‚ö° Using {config.MAX_CONCURRENT_IMAGES} parallel workers\n"
                f"{mode_emoji} Mode: {mode_name}\n"
                f"ü§ñ AI Model: {config.GEMINI_MODEL}"
            )
            
            async def update_progress(current: int, total: int):
                try:
                    progress = (current / total) * 100
                    await message.edit_text(
                        f"üîç Processing pages: {current}/{total}\n"
                        f"üìä Progress: {progress:.1f}%\n"
                        f"{mode_emoji} {mode_name} Mode\n"
                        f"‚ö° Parallel processing enabled"
                    )
                except:
                    pass
            
            all_questions = await PDFProcessor.process_images_parallel(images, mode, update_progress)
            
            if not all_questions:
                await message.edit_text("‚ùå No questions found in the PDF")
                return
            
            await message.edit_text(f"üìä Generating CSV with {len(all_questions)} questions...")
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            csv_path = config.OUTPUT_DIR / f"questions_{mode}_{user_id}_{timestamp}.csv"
            
            CSVGenerator.questions_to_csv(all_questions, csv_path)
            
            await message.edit_text("‚úÖ Sending CSV file...")
            
            with open(csv_path, 'rb') as csv_file:
                await context.bot.send_document(
                    chat_id=user_id,
                    document=csv_file,
                    filename=f"mcq_{mode}_{timestamp}.csv",
                    caption=f"‚úÖ {len(all_questions)} questions processed!\n{mode_emoji} Mode: {mode_name}\nü§ñ {config.GEMINI_MODEL}"
                )
            
            await message.edit_text(
                f"‚úÖ Done!\n\n"
                f"üìù Total questions: {len(all_questions)}\n"
                f"üìÑ Pages processed: {len(images)}\n"
                f"{mode_emoji} Mode: {mode_name}\n"
                f"‚ö° Processing: {config.MAX_CONCURRENT_IMAGES}x speed"
            )
            
            pdf_path.unlink(missing_ok=True)
            csv_path.unlink(missing_ok=True)
            if user_id in self.user_states:
                del self.user_states[user_id]
            
        except Exception as e:
            await context.bot.send_message(
                chat_id=user_id,
                text=f"‚ùå Error processing PDF: {str(e)}"
            )
            if pdf_path.exists():
                pdf_path.unlink(missing_ok=True)
            if user_id in self.user_states:
                del self.user_states[user_id]

# Main application
def main():
    bot = TelegramBot()
    application = Application.builder().token(config.TELEGRAM_BOT_TOKEN).build()
    
    # Start queue processor
    queue_processor = QueueProcessor(bot)
    asyncio.create_task(queue_processor.start())
    
    application.add_handler(CommandHandler("start", bot.start))
    application.add_handler(CommandHandler("help", bot.help_command))
    application.add_handler(CommandHandler("model", bot.model_command))
    application.add_handler(CommandHandler("queue", bot.queue_command))
    application.add_handler(CommandHandler("cancel", bot.cancel_command))
    application.add_handler(MessageHandler(filters.Document.PDF, bot.handle_document))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, bot.handle_text))
    application.add_handler(CallbackQueryHandler(bot.button_callback))
    
    print("ü§ñ Bot started successfully!")
    print(f"ü§ñ AI Model: {config.GEMINI_MODEL}")
    print(f"‚ö° Parallel processing: {config.MAX_CONCURRENT_IMAGES} concurrent images")
    print(f"üìã Max queue size: {config.MAX_QUEUE_SIZE} tasks")
    print(f"üîë API Keys: {len(config.GEMINI_API_KEYS)}")
    
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == "__main__":
    main()
